{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C://Users/ismail/Documents/TP5/calendar.csv\n",
      "C://Users/ismail/Documents/TP5/sales_train_evaluation.csv\n",
      "C://Users/ismail/Documents/TP5/sales_train_validation.csv\n",
      "C://Users/ismail/Documents/TP5/sample_submission.csv\n",
      "C://Users/ismail/Documents/TP5/sell_prices.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('C://Users/ismail/Documents/TP5/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_cal = pd.read_csv('C://Users/ismail/Documents/TP5/calendar.csv')\n",
    "df_eval = pd.read_csv('C://Users/ismail/Documents/TP5/sales_train_evaluation.csv')\n",
    "df_price = pd.read_csv('C://Users/ismail/Documents/TP5/sell_prices.csv')\n",
    "df_sample_output = pd.read_csv('C://Users/ismail/Documents/TP5/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday = ['NewYear', 'OrthodoxChristmas', 'MartinLutherKingDay', 'SuperBowl', 'PresidentsDay', 'StPatricksDay', 'Easter', 'Cinco De Mayo', 'IndependenceDay', 'EidAlAdha', 'Thanksgiving', 'Christmas']\n",
    "weekend = ['Saturday', 'Sunday']\n",
    "\n",
    "df_cal['is_holiday_1'] = df_cal['event_name_1'].apply(lambda x : 1 if x in holiday else 0 )\n",
    "df_cal['is_holiday_2'] = df_cal['event_name_1'].apply(lambda x : 1 if x in holiday else 0 )\n",
    "df_cal['is_holiday'] = df_cal[['is_holiday_1','is_holiday_2']].max(axis=1)\n",
    "df_cal['is_weekend'] = df_cal['weekday'].apply(lambda x : 1 if x in weekend else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal = df_cal.drop(['weekday', 'wday', 'month', 'year', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_col = []\n",
    "for x in range(1851):\n",
    "    del_col.append('d_' + str(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = df_eval.drop(del_col, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2744100, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id       d  qty  \n",
       "0       CA  d_1852    0  \n",
       "1       CA  d_1852    0  \n",
       "2       CA  d_1852    0  \n",
       "3       CA  d_1852    1  \n",
       "4       CA  d_1852    0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = df_eval.melt(['id','item_id','dept_id','cat_id','store_id','state_id'], var_name='d', value_name='qty')\n",
    "print(df_eval.shape)\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.merge(df_eval, df_cal, how='left', on='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.merge(df_eval, df_price, how='left', on=['item_id', 'wm_yr_wk', 'store_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_test = df_eval.query('d == \"d_1852\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_test = df_eval_test[['id', 'store_id', 'item_id', 'dept_id', 'cat_id', 'state_id', 'd', 'qty', 'sell_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_test['qty'] = df_eval_test['d'].apply(lambda x: int(x.replace(x, '0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df_eval_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9312\\507363638.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_eval_test = df_eval_test.append(tmp_df)\n"
     ]
    }
   ],
   "source": [
    "for x in range(28):\n",
    "    df_eval_test = df_eval_test.append(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_test = df_eval_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_d = []\n",
    "i = 0\n",
    "lst_index = df_eval_test.index\n",
    "for x in lst_index:\n",
    "    lst_d.append('d_' + str(((lst_index[i]) // 30490) + 1942))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_test['d'] = lst_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_test = pd.merge(df_eval_test, df_cal, how='left', on='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_test = pd.merge(df_eval_test, df_price, how='left', on=['item_id', 'wm_yr_wk', 'store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del tmp_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.get_dummies(data=df_eval, columns=['dept_id', 'cat_id', 'store_id', 'state_id'])\n",
    "df_eval_test = pd.get_dummies(data=df_eval_test, columns=['dept_id', 'cat_id', 'store_id', 'state_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_test = df_eval_test.drop(['sell_price_x', 'snap_CA', 'snap_TX', 'snap_WI'], axis='columns')\n",
    "df_eval_test = df_eval_test.rename(columns={'sell_price_y': 'sell_price'})\n",
    "df_eval = df_eval.drop(['snap_CA', 'snap_TX', 'snap_WI'], axis='columns')                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target_col = 'qty'\n",
    "exclude_cols = ['id', 'item_id', 'd', 'date', 'wm_yr_wk']\n",
    "feature_cols = [col for col in df_eval.columns if col not in exclude_cols]\n",
    "y = np.array(df_eval[target_col])\n",
    "X = np.array(df_eval[feature_cols])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.5-py3-none-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\ismail\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\ismail\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ismail\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\ismail\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ismail\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ismail\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ismail\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\ismail\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\ismail\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.414929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 379\n",
      "[LightGBM] [Info] Number of data points in the train set: 2058075, number of used features: 29\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Info] Start training from score 1.395218\n",
      "Training until validation scores don't improve for 1500 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's rmse: 3.1763\n",
      "[100]\tvalid_0's rmse: 2.75736\n",
      "[150]\tvalid_0's rmse: 2.4468\n",
      "[200]\tvalid_0's rmse: 2.17382\n",
      "[250]\tvalid_0's rmse: 1.91874\n",
      "[300]\tvalid_0's rmse: 1.71201\n",
      "[350]\tvalid_0's rmse: 1.50441\n",
      "[400]\tvalid_0's rmse: 1.36319\n",
      "[450]\tvalid_0's rmse: 1.22157\n",
      "[500]\tvalid_0's rmse: 1.06647\n",
      "[550]\tvalid_0's rmse: 0.959698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's rmse: 0.872827\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[650]\tvalid_0's rmse: 0.777221\n",
      "[700]\tvalid_0's rmse: 0.689222\n",
      "[750]\tvalid_0's rmse: 0.609335\n",
      "[800]\tvalid_0's rmse: 0.558696\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[850]\tvalid_0's rmse: 0.502956\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[900]\tvalid_0's rmse: 0.46231\n",
      "[950]\tvalid_0's rmse: 0.421116\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's rmse: 0.385276\n",
      "[1050]\tvalid_0's rmse: 0.36201\n",
      "[1100]\tvalid_0's rmse: 0.337665\n",
      "[1150]\tvalid_0's rmse: 0.314366\n",
      "[1200]\tvalid_0's rmse: 0.298203\n",
      "[1250]\tvalid_0's rmse: 0.283264\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1300]\tvalid_0's rmse: 0.26973\n",
      "[1350]\tvalid_0's rmse: 0.257903\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1400]\tvalid_0's rmse: 0.247851\n",
      "[1450]\tvalid_0's rmse: 0.238338\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1500]\tvalid_0's rmse: 0.230708\n",
      "[1550]\tvalid_0's rmse: 0.22418\n",
      "[1600]\tvalid_0's rmse: 0.218226\n",
      "[1650]\tvalid_0's rmse: 0.213593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1700]\tvalid_0's rmse: 0.208771\n",
      "[1750]\tvalid_0's rmse: 0.204243\n",
      "[1800]\tvalid_0's rmse: 0.200397\n",
      "[1850]\tvalid_0's rmse: 0.19673\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1900]\tvalid_0's rmse: 0.193595\n",
      "[1950]\tvalid_0's rmse: 0.190888\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2000]\tvalid_0's rmse: 0.188689\n",
      "[2050]\tvalid_0's rmse: 0.186356\n",
      "[2100]\tvalid_0's rmse: 0.184361\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2150]\tvalid_0's rmse: 0.182574\n",
      "[2200]\tvalid_0's rmse: 0.180866\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2250]\tvalid_0's rmse: 0.17942\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2300]\tvalid_0's rmse: 0.178061\n",
      "[2350]\tvalid_0's rmse: 0.1767\n",
      "[2400]\tvalid_0's rmse: 0.175754\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2450]\tvalid_0's rmse: 0.17458\n",
      "[2500]\tvalid_0's rmse: 0.17362\n",
      "[2550]\tvalid_0's rmse: 0.172659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2600]\tvalid_0's rmse: 0.171863\n",
      "[2650]\tvalid_0's rmse: 0.171201\n",
      "[2700]\tvalid_0's rmse: 0.170388\n",
      "[2750]\tvalid_0's rmse: 0.1699\n",
      "[2800]\tvalid_0's rmse: 0.169239\n",
      "[2850]\tvalid_0's rmse: 0.168683\n",
      "[2900]\tvalid_0's rmse: 0.168162\n",
      "[2950]\tvalid_0's rmse: 0.167609\n",
      "[3000]\tvalid_0's rmse: 0.167221\n",
      "[3050]\tvalid_0's rmse: 0.166831\n",
      "[3100]\tvalid_0's rmse: 0.166437\n",
      "[3150]\tvalid_0's rmse: 0.166042\n",
      "[3200]\tvalid_0's rmse: 0.165668\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3250]\tvalid_0's rmse: 0.165367\n",
      "[3300]\tvalid_0's rmse: 0.165201\n",
      "[3350]\tvalid_0's rmse: 0.164951\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3400]\tvalid_0's rmse: 0.16463\n",
      "[3450]\tvalid_0's rmse: 0.164402\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3500]\tvalid_0's rmse: 0.16416\n",
      "[3550]\tvalid_0's rmse: 0.163957\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3600]\tvalid_0's rmse: 0.163815\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3650]\tvalid_0's rmse: 0.163638\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3700]\tvalid_0's rmse: 0.163526\n",
      "[3750]\tvalid_0's rmse: 0.163367\n",
      "[3800]\tvalid_0's rmse: 0.163315\n",
      "[3850]\tvalid_0's rmse: 0.163268\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3900]\tvalid_0's rmse: 0.163023\n",
      "[3950]\tvalid_0's rmse: 0.162911\n",
      "[4000]\tvalid_0's rmse: 0.162856\n",
      "[4050]\tvalid_0's rmse: 0.162761\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4100]\tvalid_0's rmse: 0.162658\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4150]\tvalid_0's rmse: 0.162615\n",
      "[4200]\tvalid_0's rmse: 0.16252\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4250]\tvalid_0's rmse: 0.162567\n",
      "[4300]\tvalid_0's rmse: 0.16245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4350]\tvalid_0's rmse: 0.162443\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4400]\tvalid_0's rmse: 0.162385\n",
      "[4450]\tvalid_0's rmse: 0.162296\n",
      "[4500]\tvalid_0's rmse: 0.1623\n",
      "[4550]\tvalid_0's rmse: 0.162325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4600]\tvalid_0's rmse: 0.162295\n",
      "[4650]\tvalid_0's rmse: 0.162249\n",
      "[4700]\tvalid_0's rmse: 0.162242\n",
      "[4750]\tvalid_0's rmse: 0.162282\n",
      "[4800]\tvalid_0's rmse: 0.162203\n",
      "[4850]\tvalid_0's rmse: 0.162161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4900]\tvalid_0's rmse: 0.162156\n",
      "[4950]\tvalid_0's rmse: 0.162138\n",
      "[5000]\tvalid_0's rmse: 0.162129\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4986]\tvalid_0's rmse: 0.162114\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "\n",
    "params = {\n",
    "        'n_jobs': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 64,\n",
    "        \"learning_rate\" : 0.005,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.5,\n",
    "        \"bagging_frequency\" : 6,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbosity\" : 1,\n",
    "        \"seed\": 42,\n",
    "        }\n",
    "\n",
    "\n",
    "evals_result = {}\n",
    "\n",
    "model = lgb.train(params, lgb_train, 5000, \n",
    "                      valid_sets=[lgb_eval], \n",
    "                      early_stopping_rounds=1500, \n",
    "                      verbose_eval=50, \n",
    "                      evals_result=evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(df_eval_test[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_test['pred_qty'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>NaN</th>\n",
       "      <th>2016-05-23</th>\n",
       "      <th>2016-05-24</th>\n",
       "      <th>2016-05-25</th>\n",
       "      <th>2016-05-26</th>\n",
       "      <th>2016-05-27</th>\n",
       "      <th>2016-05-28</th>\n",
       "      <th>2016-05-29</th>\n",
       "      <th>2016-05-30</th>\n",
       "      <th>...</th>\n",
       "      <th>2016-06-10</th>\n",
       "      <th>2016-06-11</th>\n",
       "      <th>2016-06-12</th>\n",
       "      <th>2016-06-13</th>\n",
       "      <th>2016-06-14</th>\n",
       "      <th>2016-06-15</th>\n",
       "      <th>2016-06-16</th>\n",
       "      <th>2016-06-17</th>\n",
       "      <th>2016-06-18</th>\n",
       "      <th>2016-06-19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>0.084437</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>-0.006474</td>\n",
       "      <td>-0.006474</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>-0.006474</td>\n",
       "      <td>-0.006474</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>-0.006474</td>\n",
       "      <td>-0.006474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_2_evaluation</td>\n",
       "      <td>0.035619</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.019361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_3_evaluation</td>\n",
       "      <td>0.348475</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.001234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_001_CA_4_evaluation</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>-0.003908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_001_TX_1_evaluation</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.005741</td>\n",
       "      <td>-0.005741</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.005741</td>\n",
       "      <td>-0.005741</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.005741</td>\n",
       "      <td>-0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>HOUSEHOLD_2_516_TX_2_evaluation</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.003881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>HOUSEHOLD_2_516_TX_3_evaluation</td>\n",
       "      <td>-0.088636</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>-0.005773</td>\n",
       "      <td>-0.005773</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>-0.005773</td>\n",
       "      <td>-0.005773</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>-0.003180</td>\n",
       "      <td>-0.005773</td>\n",
       "      <td>-0.005773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_1_evaluation</td>\n",
       "      <td>-0.120247</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>-0.003348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_2_evaluation</td>\n",
       "      <td>0.931745</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.004662</td>\n",
       "      <td>-0.004662</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.004662</td>\n",
       "      <td>-0.004662</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.004662</td>\n",
       "      <td>-0.004662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>-0.036236</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>-0.004220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                                id       NaN  2016-05-23  2016-05-24  \\\n",
       "0          FOODS_1_001_CA_1_evaluation  0.084437    0.000615    0.000615   \n",
       "1          FOODS_1_001_CA_2_evaluation  0.035619    0.018037    0.018037   \n",
       "2          FOODS_1_001_CA_3_evaluation  0.348475    0.002899    0.002899   \n",
       "3          FOODS_1_001_CA_4_evaluation  0.004666    0.003304    0.003304   \n",
       "4          FOODS_1_001_TX_1_evaluation  0.025422   -0.004310   -0.004310   \n",
       "...                                ...       ...         ...         ...   \n",
       "30485  HOUSEHOLD_2_516_TX_2_evaluation -0.125231   -0.002891   -0.002891   \n",
       "30486  HOUSEHOLD_2_516_TX_3_evaluation -0.088636   -0.003180   -0.003180   \n",
       "30487  HOUSEHOLD_2_516_WI_1_evaluation -0.120247   -0.001506   -0.001506   \n",
       "30488  HOUSEHOLD_2_516_WI_2_evaluation  0.931745   -0.002552   -0.002552   \n",
       "30489  HOUSEHOLD_2_516_WI_3_evaluation -0.036236   -0.001823   -0.001823   \n",
       "\n",
       "date   2016-05-25  2016-05-26  2016-05-27  2016-05-28  2016-05-29  2016-05-30  \\\n",
       "0        0.000615    0.000615    0.000615   -0.006474   -0.006474    0.000615   \n",
       "1        0.018037    0.018037    0.018037    0.019361    0.019361    0.018037   \n",
       "2        0.002899    0.002899    0.002899    0.001234    0.001234    0.002899   \n",
       "3        0.003304    0.003304    0.003304   -0.003908   -0.003908    0.003304   \n",
       "4       -0.004310   -0.004310   -0.004310   -0.005741   -0.005741   -0.004310   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "30485   -0.002891   -0.002891   -0.002891   -0.003881   -0.003881   -0.002891   \n",
       "30486   -0.003180   -0.003180   -0.003180   -0.005773   -0.005773   -0.003180   \n",
       "30487   -0.001506   -0.001506   -0.001506   -0.003348   -0.003348   -0.001506   \n",
       "30488   -0.002552   -0.002552   -0.002552   -0.004662   -0.004662   -0.002552   \n",
       "30489   -0.001823   -0.001823   -0.001823   -0.004220   -0.004220   -0.001823   \n",
       "\n",
       "date   ...  2016-06-10  2016-06-11  2016-06-12  2016-06-13  2016-06-14  \\\n",
       "0      ...    0.000615   -0.006474   -0.006474    0.000615    0.000615   \n",
       "1      ...    0.018037    0.019361    0.019361    0.018037    0.018037   \n",
       "2      ...    0.002899    0.001234    0.001234    0.002899    0.002899   \n",
       "3      ...    0.003304   -0.003908   -0.003908    0.003304    0.003304   \n",
       "4      ...   -0.004310   -0.005741   -0.005741   -0.004310   -0.004310   \n",
       "...    ...         ...         ...         ...         ...         ...   \n",
       "30485  ...   -0.002891   -0.003881   -0.003881   -0.002891   -0.002891   \n",
       "30486  ...   -0.003180   -0.005773   -0.005773   -0.003180   -0.003180   \n",
       "30487  ...   -0.001506   -0.003348   -0.003348   -0.001506   -0.001506   \n",
       "30488  ...   -0.002552   -0.004662   -0.004662   -0.002552   -0.002552   \n",
       "30489  ...   -0.001823   -0.004220   -0.004220   -0.001823   -0.001823   \n",
       "\n",
       "date   2016-06-15  2016-06-16  2016-06-17  2016-06-18  2016-06-19  \n",
       "0        0.000615    0.000615    0.000615   -0.006474   -0.006474  \n",
       "1        0.018037    0.018037    0.018037    0.019361    0.019361  \n",
       "2        0.002899    0.002899    0.002899    0.001234    0.001234  \n",
       "3        0.003304    0.003304    0.003304   -0.003908   -0.003908  \n",
       "4       -0.004310   -0.004310   -0.004310   -0.005741   -0.005741  \n",
       "...           ...         ...         ...         ...         ...  \n",
       "30485   -0.002891   -0.002891   -0.002891   -0.003881   -0.003881  \n",
       "30486   -0.003180   -0.003180   -0.003180   -0.005773   -0.005773  \n",
       "30487   -0.001506   -0.001506   -0.001506   -0.003348   -0.003348  \n",
       "30488   -0.002552   -0.002552   -0.002552   -0.004662   -0.004662  \n",
       "30489   -0.001823   -0.001823   -0.001823   -0.004220   -0.004220  \n",
       "\n",
       "[30490 rows x 30 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = df_eval_test[['id', 'date', 'pred_qty']]\n",
    "predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'pred_qty').reset_index()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.drop(predictions.columns[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2744099 + 1 - 853720\n",
    "df_val = df_eval[x:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v = df_val[['id', 'date', 'qty']]\n",
    "predictions_v = pd.pivot(predictions_v, index = 'id', columns = 'date', values = 'qty').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v['id'] = predictions['id'].apply(lambda x: x.replace('evaluation', 'validation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_concat = pd.concat([predictions, predictions_v], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_concat.to_csv('C://Users/ismail/Documents/TP5/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
